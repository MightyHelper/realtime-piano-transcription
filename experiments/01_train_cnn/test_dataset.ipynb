{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from src.common import MaestroSplitType\n",
    "from torch.utils.data import DataLoader\n",
    "from src.maestro2 import MaestroDatasetSplit, FrameContextDataset, DynamicBatchIterableDataset2, custom_collate_fn\n",
    "from torch.nn import MSELoss, BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "dataset = MaestroDatasetSplit(MaestroSplitType.TRAIN)\n",
    "print(len(dataset.split.entries))\n",
    "dataset.split.entries = dataset.split.entries[:10]\n",
    "dataset.split.df_entries = dataset.split.df_entries[:10]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_context = 32\n",
    "n_predict = 32\n",
    "dataset2 = FrameContextDataset(dataset, n_context, n_predict)"
   ],
   "id": "d1e8385dd0b6bcb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "epochs = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "wrapped_dataset = DynamicBatchIterableDataset2(dataset2, batch_size)\n",
    "data_loader = DataLoader(\n",
    "    wrapped_dataset, \n",
    "    batch_size=1,  # Let the collate_fn handle the final batching\n",
    "    collate_fn=custom_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=(dataset2[0][0].shape[0]*4) // (batch_size * num_workers),\n",
    "    multiprocessing_context='spawn',\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=device,\n",
    ")\n",
    "len(data_loader)"
   ],
   "id": "d64f8edec0dc52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "952f40a00c503b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model import get_model2\n",
    "model = get_model2(n_predict, device)\n",
    "# initialize the weights\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(0.2)\n",
    "    elif type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(0.2)\n",
    "        \n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "## Pass dummy batch\n",
    "x, y = next(iter(dataset2))\n",
    "x = x[1000:1101].transpose(1, 2).unsqueeze(1).cuda()\n",
    "y = y[1000:1101].transpose(1, 2).unsqueeze(1).cuda()\n",
    "x = (x - x.mean()) / x.std()\n",
    "y = y / 100.\n",
    "print(x.shape, y.shape)\n",
    "y_ = model.forward(x)\n",
    "print(y_.shape)\n",
    "loss = MSELoss()\n",
    "\n",
    "l = loss(y, y_)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params, l.item()"
   ],
   "id": "e9550eb1e492c615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1f6811d61401bf4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.min(), y.max(), y_.min(), y_.max()",
   "id": "e29bfd67cabfbc42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.shape, y_.shape, y.shape",
   "id": "3e05ec69e3cfce12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y[0, 0, :, 29]",
   "id": "34f9d3ac50741561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dataset.split.entries[0].load_audio.display_ipython(0., 10.)\n",
    "xc = x.detach().cpu().squeeze(1)\n",
    "y_c = y_.detach().cpu().squeeze(1)\n",
    "yc = y.detach().cpu().squeeze(1)\n",
    "# 1001, 32, 229\n",
    "# To 1001, 229\n",
    "xc = xc[:, 0, :]\n",
    "y_c = y_c[:, 0, :]\n",
    "yc = yc[:, 0, :]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(xc[:5000, :].transpose(0, 1), cmap='gray', interpolation='none')\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(y_c[:5000, :].transpose(0, 1), cmap='gray', interpolation='none')\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(yc[:5000, :].transpose(0, 1), cmap='gray', interpolation='none')\n",
    "plt.show()"
   ],
   "id": "9109008abf5b3550",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_c.std(axis=0).max()",
   "id": "c38d79eb763a2274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import wandb\n",
   "id": "7feddd9a15d38d59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"realtime-piano-transcription\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Basic-CNN-v2\",\n",
    "        \"dataset\": \"MAESTRO-Validation\",\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    ")"
   ],
   "id": "d5397cc373da36fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from wandb import watch\n",
    "\n",
    "watch(model)"
   ],
   "id": "eddce12aaee65452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    with tqdm(total=len(data_loader)) as pbar:\n",
    "        total_loss = 0\n",
    "        for idx, (x, y) in enumerate(data_loader):\n",
    "            x = x.transpose(1, 2).unsqueeze(1).cuda()\n",
    "            # Normalize x\n",
    "            x = (x - x.mean()) / x.std()\n",
    "            # Expand y from (batch, key, n_predict) to (batch, mel_bin, key); where key = 128, and mel_bin = 229; do this by padding with zeros\n",
    "            y = y.transpose(1, 2).unsqueeze(1).cuda()\n",
    "            y = y / 100.\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss_val = loss(output, y)\n",
    "            loss_val.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss_val.item()\n",
    "            pbar.update(1)\n",
    "            wandb.log({'train_loss': loss_val.item(), 'epoch': epoch, 'batch': idx})\n",
    "        text = f'Epoch {epoch} - Loss: {total_loss}'\n",
    "        pbar.set_description(text)\n",
    "        print(text)\n"
   ],
   "id": "b23460f6d4eb3b6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "dfba378b9d6f89a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for param in model.parameters():\n",
    "    print(param.grad.norm())"
   ],
   "id": "f5a5d1ea3615b887",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fx, fy = next(iter(dataset2))\n",
    "x = fx[1000:1101].transpose(1, 2).unsqueeze(1).cuda()\n",
    "y = fy[1000:1101].transpose(1, 2).unsqueeze(1).cuda()\n",
    "x = (x - x.mean()) / x.std()\n",
    "y = y / 100.\n",
    "y_ = model.forward(x)\n",
    "l = loss(y, y_)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params, l.item()"
   ],
   "id": "e829f60d715f66df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.min(), y.max(), y_.min(), y_.max()",
   "id": "c9f9c56ae254b80e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fy.shape.numel() / fy.count_nonzero()",
   "id": "583d2c1beb437caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_c = y_.detach().cpu()\n",
    "yc = y.detach().cpu()"
   ],
   "id": "31f10152fbeb9ca6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display(plt.imshow(y_c[0, 0, :, :].transpose(0, 1), cmap='gray', interpolation='none'))"
   ],
   "id": "dfde686aa8c5a233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(plt.imshow(yc[0, 0, :, :].transpose(0, 1), cmap='gray', interpolation='none'))",
   "id": "fadf4fb73a7e70a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# torch.save(model.state_dict(), 'model2.pth')",
   "id": "f4a5b3930eb1dd4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
